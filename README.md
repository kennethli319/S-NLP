# Speech and Natural Language Processing
  This page shows some of the open source projects, toolkits and websites which are typically useful for researches or applications in speech and language processing.

Other lists for SNLP:
<a href="https://github.com/edobashira/speech-language-processing">[List1-Github-SNLP]</a>
<a href="https://zhuanlan.zhihu.com/p/25887325">[List2-Zhihu-SNLP]</a>
<a href="https://github.com/candlewill/Speech-Corpus-Collection">[List3-Github-Speech]</a> 
<br>

Jump to:
<a href="#speech">[Speech]</a>
<a href="#nlp">[NLP]</a>
<a href="#ml">[Machine Learning and Neural Net]</a>
<a href="#paper">[Research]</a>
<a href="#courses">[Courses]</a>

---
## Speech related:
<div id="speech">
  <ol>
  <li>
    <b> CMUSphinx </b> <a href="https://cmusphinx.github.io/">[link]</a> <br>
    OPEN SOURCE SPEECH RECOGNITION TOOLKIT <br>
  </li>

  <li>
    <b>Festival</b> <a href="http://www.cstr.ed.ac.uk/projects/festival/">[link]</a> <a href="http://www.festvox.org/docs/manual-2.4.0/festival_toc.html">[documentation]</a> <br>
    Speech Synthesis System by CSTR <br>
  </li>

  <li>
    <b>Speech-Corpus-Collection</b> <a href="https://github.com/candlewill/Speech-Corpus-Collection">[link]</a> <br>
  </li>

  <li>
    <b>Kaldi ASR</b> <a href="http://kaldi-asr.org/">[link]</a> <br>
  </li>

  <li>
    <b>Praat</b> <a href="http://www.fon.hum.uva.nl/praat/">[link]</a> <br>
  </li>

  <li>
    <b>LibriSpeech ASR corpus</b> <a href="https://www.openslr.org/12">[link]</a> <br>
    Large-scale (1000 hours) corpus of read English speech <br>
  </li>

  <li>
    <b>Common voice</b> <a href="https://github.com/mozilla/voice-web">[Github]</a> <a href="https://voice.mozilla.org/">[website]</a> <br>
    Common Voice is Mozilla's initiative to help teach machines how real people speak. <br>
    https://github.com/mozilla/voice-web/tree/master/server/data/zh-HK
  </li>
  
  <li>
    <b>TED-LIUM Release 3</b> <a href="https://www.openslr.org/51/">[link]</a> <br>
    452 hours of audio <br>
  </li>

  <li>
    <b>VoxForge</b> <a href="http://www.repository.voxforge1.org/downloads/SpeechCorpus/Trunk/">[link]</a> <br>
    VoxForge was set up to collect transcribed speech for use in Open Source Speech Recognition Engines ("SRE"s) such as such as ISIP, HTK, Julius and Sphinx.<br>
  </li>
  
  <li>
    <b>Tatoeba</b> <a href="https://tatoeba.org/eng/downloads">[link]</a> <br>
    Tatoeba is a collection of sentences and translations. <br>
  </li>
  
  <li>
    <b>EMIME Project</b> <a href="http://www.emime.org/">[link]</a> <br>
  </li>
  
  <li>
    <b>CMU_ARCTIC speech synthesis databases</b> <a href="http://festvox.org/cmu_arctic/">[link]</a> <br>
  </li>
  
  <li>
    <b>The World English Bible</b> <a href="http://www.audiotreasure.com/webindex.htm">[link]</a> <br>
  </li>
  
  <li>
    <b>Nancy Corpus</b> <a href="http://www.cstr.ed.ac.uk/projects/blizzard/2011/lessac_blizzard2011/">[link]</a> <br>
  </li>
  
  <li>
    <b>Google uis-rnn</b> <a href="https://github.com/google/uis-rnn">[Github]</a> <a href="https://arxiv.org/abs/1810.04719">[paper]</a> <br>
    This is the library for the Unbounded Interleaved-State Recurrent Neural Network (UIS-RNN) algorithm, corresponding to the paper Fully Supervised Speaker Diarization. 
  </li>

  <li>
    <b>A simple interface for the CMU pronouncing dictionary </b> <a href="https://github.com/aparrish/pronouncingpy">[link]</a> <br>
  </li>
  
  <li>
    <b>E-Guide dog</b> <a href="https://www.oschina.net/question/3820517_2280583">[link]</a> <br>
  </li>

  <li>
    <b>PyTorch implementation of GAN-based text-to-speech synthesis and voice conversion (VC) </b> <a href="https://github.com/r9y9/gantts">[link]</a> <br>
  </li>

  <li>
    <b> Something useful for speech and natural language processing </b> <a href="https://github.com/MU94W/SpeechUtils">[link]</a> <br>
    Something useful for speech and natural language processing <br>
  </li>

  <li>
    <b> Saarbruecken Voice Database </b> <a href="http://stimmdb.coli.uni-saarland.de/index.php4#target">[link]</a> <br>
  </li>

  <li>
    <b> A British National Corpus Spoken Audio Sampler </b> <a href="http://www.phon.ox.ac.uk/SpokenBNC">[link]</a> <br>
    This site presents a selection of audio files from the spoken part of the British National Corpus, digitized from the analogue audio cassette tapes deposited at the British Library Sound Archive, together with associated transcription and annotation files created during the Mining a Year of Speech project. <br>
  </li>

  <li>
    <b> pronouncingpy </b> <a href="https://github.com/aparrish/pronouncingpy">[link]</a> <br>
    A simple interface for the CMU pronouncing dictionary <br>
  </li>

  <li>
    <b> Sound & MIDI Software For Linux </b> <a href="http://linux-sound.org/one-page.html">[link]</a> <br>
  </li>

  <li>
    <b> Linguistic Variation in Chinese Speech Communities 泛華語地區漢語共時語料庫 </b> <a href="http://hkcc.livac.org/index.php?lang=tc">[link]</a> <br>
  </li>


  <li>
    <b> Pyworld </b> <a href="https://github.com/JeremyCCHsu/Python-Wrapper-for-World-Vocoder">[link]</a> <br>
    A Python wrapper for the high-quality vocoder "World" <br>
  </li>

  <li>
    <b> NAME </b> <a href="LINK">[link]</a> <br>
    INFO <br>
  </li>

  </ol>
</div>

## NLP related:
<div id="nlp">
  <ol>
  
  <li>
    <b>BBC news corpus</b> <a href="http://mlg.ucd.ie/datasets/bbc.html">[link]</a> <br>
  </li>
  
  <li>
    <b>GEO query database</b> <a href="http://www.cs.utexas.edu/users/ml/nldata/geoquery.html">[link]</a> <br>
  </li>
  
  <li>
    <b>FreeBase for QA</b> <a href="https://www.freebase.com/">[link]</a> <br>
  </li>
  
  <li>
    <b>Google Bert </b> <a href="https://github.com/google-research/bert">[link]</a> <br>
    TensorFlow code and pre-trained models for BERT https://arxiv.org/abs/1810.04805
  </li>
  
  <li>
    <b>Google Dialogflow(previously api.ai) </b> <a href="https://dialogflow.com/">[link]</a> <br>
  </li>

  <li>
    <b> DouBan DuShu </b> <a href="https://github.com/JaniceZhao/Douban-Dushu-Dataset">[link]</a> <br>
    DouBan DuShu is a Chinese website where users can share their reviews about various kinds of books. <br>
  </li>
  
  <li>
    <b> Chinese-Forum-Corpus </b> <a href="https://github.com/JaniceZhao/Chinese-Forum-Corpus.git">[link]</a> <br>
    Chinese-Forum-Corpus is a corpus of informal Chinese text <br>
  </li>

  <li>
    <b> CLAMP </b> <a href="https://clamp.uth.edu ">[link]</a> <br>
    Clinical Language Annotation, Modeling, and Processing Toolkit <br>
  </li>

  <li>
    <b> Bytecup2018 </b> <a href="https://www.dropbox.com/sh/fum6rxzx66bz5dl/AABLGonlZvj5m6LzqGgUsb6ga?dl=0">[link]</a> <br>
    Bytecup Dataset <br>
  </li>

  <li>
    <b> Facebook fastText </b> <a href="https://github.com/facebookresearch/fastText">[link]</a> <br>
    fastText is a library for efficient learning of word representations and sentence classification. <br>
  </li>

  <li>
    <b> 開放中文轉換（Pure Python） </b> <a href="https://github.com/yichen0831/opencc-python/blob/master/README.md">[link]</a> <br>
    Open Chinese convert (OpenCC) in pure Python. <br>
  </li>

  <li>
    <b> pkuseg-python </b> <a href="https://github.com/lancopku/pkuseg-python">[link]</a> <br>
    pkuseg 是由北京大学语言计算与机器学习研究组研制推出的一套全新的中文分词工具包。 <br>
  </li>

  <li>
    <b> OpenAI GPT-2 </b> <a href="https://github.com/openai/gpt-2">[link]</a> <br>
    Code for the paper "Language Models are Unsupervised Multitask Learners" <br>
  </li>
  
<<<<<<< Updated upstream
=======
  <li>
    <b> NAME </b> <a href="LINK">[link]</a> <br>
    INFO <br>
  </li>

>>>>>>> Stashed changes
  <li>
    <b> NAME </b> <a href="LINK">[link]</a> <br>
    INFO <br>
  </li>
  
  </ol>
</div>

## Machine Learning / Neural Network related:
<div id="ml">
  <ol>
  <li>
    <b> An MIT Press book by Ian Goodfellow and Yoshua Bengio and Aaron Courville </b> <a href="https://www.deeplearningbook.org/">[link]</a> <br>
  </li>
  
  <li>
    <b> Deepmind trfl </b> <a href="https://github.com/deepmind/trfl/">[link]</a> <br>
  </li>
  
  <li>
    <b> Dopamine is a research framework for fast prototyping of reinforcement learning algorithms </b> <a href="https://github.com/google/dopamine">[link]</a> <br>
  </li>

  <li>
    <b> Neural Networks and Deep Learning, a free online book </b> <a href="http://neuralnetworksanddeeplearning.com/">[link]</a> <br>
  </li>
  
  <li>
    <b> TensorSpace.js </b> <a href="https://github.com/tensorspace-team/tensorspace">[link]</a> <br>
    A neural network 3D visualization framework built by TensorFlow.js, Three.js and Tween.js
  </li>

  <li>
    <b> Deep Reinforcement Learning for Keras </b> <a href="https://github.com/keras-rl/keras-rl">[link]</a> <br>
    keras-rl implements some state-of-the art deep reinforcement learning algorithms in Python and seamlessly integrates with the deep learning library Keras. <br>
  </li>

  <li>
    <b> 《Attention is All You Need》中的Attention机制的实现 </b> <a href="https://github.com/bojone/attention">[link]</a> <br>
  </li>

  <li>
    <b> NAME </b> <a href="LINK">[link]</a> <br>
    INFO <br>
  </li>

  </ol>
</div>

## Research paper:
<div id="paper">
  <ol>
  <li>
    <b> One Model To Learn Them All </b> <a href="https://arxiv.org/abs/1706.05137">[link]</a> <br>
    #2017 #MultiTasking <br>
  </li>

  <li>
    <b> Attention Is All You Need </b> <a href="https://arxiv.org/abs/1706.03762">[link]</a> <br>
    #2017 #NeuralNetwork #Attention <br>
  </li>

  <li>
    <b> Low-Resource Speech-to-Text Translation </b> <a href="https://arxiv.org/pdf/1803.09164.pdf">[link]</a> <br>
  </li>

  <li>
    <b> speech-to-speech translation </b> <a href="https://scholar.google.co.uk/scholar?as_ylo=2018&q=speech-to-speech+translation&hl=en&as_sdt=0,5&as_vis=1">[link]</a> <br>
  </li>

  <li>
    <b> Psychlab: A Psychology Laboratory for Deep Reinforcement Learning Agents </b> <a href="https://arxiv.org/pdf/1801.08116.pdf">[link]</a> <br>
  </li>

  <li>
    <b> Multimodal Machine Translation with Reinforcement Learning </b> <a href="https://arxiv.org/pdf/1805.02356.pdf">[link]</a> <br>
  </li>

  <li>
    <b> Exploiting Linguistic Resources for Neural Machine Translation Using Multi-task Learning </b> <a href="https://arxiv.org/pdf/1708.00993.pdf">[link]</a> <br>
  </li>

  <li>
    <b> Self-managed Speech Therapy </b> <a href="https://www.tdcommons.org/cgi/viewcontent.cgi?article=2474&context=dpubs_series">[link]</a> <br>
    #2018 #SpeechTherapy <br>
  </li>

  <li>
    <b> Voice-based determination of physical and emotional characteristics of users </b> <a href="https://patentimages.storage.googleapis.com/f6/a2/36/d99e36720ad953/US10096319.pdf">[link]</a> <br>
    Systems, methods, and computer-readable media are disclosed for voice-based determination of physical and emotional characteristics of users. Example methods may include determining first voice data, wherein the first voice data is generated by a user, determining a first real-time user status of the user using the first voice data, generating a first data tag indicative of the first real-time user status, determining first audio content for presentation at a speaker device using the first data tag and the first voice data, and causing presentation of the first audio content via a speaker of the speaker device. <br>
  </li>

  <li>
    <b> 香港成人粵語口語語料庫 </b> <a href="http://www.cuhk.edu.hk/ics/clrc/crcl_92_1/fung.pdf">[link]</a> <br>
    INFO <br>
  </li>

  <li>
    <b> 粵語研究新資源：《香港二十世紀中期粵語語料庫》</b> <a href="https://www.researchgate.net/publication/280004764_yueyuyanjiuxinziyuanxianggangershishijizhongqiyueyuyuliaoku">[link]</a> <br>  
    mentioned (1) 香港兒童粵語語料庫（Hong Kong Cantonese Child Language Corpus - CANCORP）（Lee and Wong 1998）(2)  香港雙語兒童語料庫（Yip and Matthews 2007）(3)  香港粵語語料庫（Hong Kong University Cantonese Corpus）（Wong 2006）(4)   The Hong Kong Cantonese Adult Corpus（Leung and Law 2001） <br>
  </li>

  <li>
    <b> Large-Scale Study of Curiosity-Driven Learning </b> <a href="https://pathak22.github.io/large-scale-curiosity/resources/largeScaleCuriosity2018.pdf">[link]</a> <br>
    Curiosity-Driven RL <br>
  </li>
  
  <li>
    <b> SeqGAN: Sequence Generative Adversarial Nets with Policy Gradient </b> <a href="https://arxiv.org/pdf/1609.05473.pdf">[link]</a> <br>
    #2017 <br>
  </li>

  <li>
    <b> Recent Trends in Deep Learning Based Natural Language Processing </b> <a href="https://ieeexplore.ieee.org/abstract/document/8416973">[link]</a> <br>
    #2018 <br>
  </li>

  <li>
    <b> SEQUENCE-TO-SEQUENCE ASR OPTIMIZATION VIA REINFORCEMENT LEARNING </b> <a href="https://arxiv.org/pdf/1710.10774.pdf">[link]</a> <br>
  </li>

  <li>
    <b> Listen, Attend and Spell </b> <a href="https://arxiv.org/pdf/1508.01211.pdf">[link]</a> <br>
     Listen, Attend and Spell (LAS), a neural network that learns to transcribe speech utterances to characters. <br>
  </li>

  <li>
    <b> State-of-the-Art Speech Recognition with Sequence-to-Sequence Models </b> <a href="https://ieeexplore.ieee.org/abstract/document/8462105">[link]</a> <br>
    Attention-based encoder-decoder architectures such as Listen, Attend, and Spell (LAS), subsume the acoustic, pronunciation and language model components of a traditional automatic speech recognition (ASR) system into a single neural network. On a 12, 500 hour voice search task, we find that the proposed changes improve the WER from 9.2% to 5.6%, while the best conventional system achieves 6.7%; on a dictation task our model achieves a WER of 4.1% compared to 5% for the conventional system. <br>
  </li>

  <li>
    <b> PyText </b> <a href="https://code.fb.com/ai-research/pytext-open-source-nlp-framework/">[link]</a> <br>
    Open-sourcing PyText for faster NLP development <br>
  </li>

 <li>
    <b> NAME </b> <a href="LINK">[link]</a> <br>
    INFO <br>
  </li>

  </ol>
</div>

## Courses
<div id="courses">
  <ol>
  <li>
    <b> Oxford Deep NLP 2017 course </b> <a href="https://github.com/oxford-cs-deepnlp-2017">[link]</a> <br>
  </li>

  <li>
    <b> Deepmind UCL Deep RL </b> <a href="https://www.youtube.com/watch?v=ISk80iLhdfU">[link]</a> <br>
  </li>

  <li>
    <b> Steps by steps - learn Computer Science and Artificial Intelligence </b> <a href="https://github.com/congchan/Computer-Science-and-Artificial-Intelligence">[link]</a> <br>
  </li>

  <li>
    <b> AI For Everyone - Coursera </b> <a href="https://www.coursera.org/learn/ai-for-everyone/">[link]</a> <br>
  </li>

  <li>
    <b> Neural Networks and Deep Learning </b> <a href="neuralnetworksanddeeplearning.com">[link]</a> <br>
    Neural networks and deep learning currently provide the best solutions to many problems in image recognition, speech recognition, and natural language processing. This book will teach you many of the core concepts behind neural networks and deep learning. <br>
  </li>

  <li>
    <b> Introduction to Digital Speech Processing 數位語音處理概論 - 李琳山教授 </b> <a href="http://ocw.aca.ntu.edu.tw/ntu-ocw/ocw/cou/104S204/1">[link]</a> <br>
    本課程專為大學部同學所開授。所需要的最主要基礎能力是數學模型(機率、線性代數)及軟體程式，所有難題由數學模型分析，並由程式求解；其中大部份核心觀念均與機器學習(Machine Learning) <br>
  </li>

  <li>
    <b> Merlin:中文统计参数语音合成实战 </b> <a href="https://sentiment-mining.blogspot.com/2017/07/merlin.html">[link]</a> <br>
    本文目标是详细解释如何基于开源Merlin项目搭建中文统计参数语音合成系统，但笔者目前尚未实现中文语音合成，本文记录了笔者的进展并且会持续更新直到实现中文语音合成为止。 <br>
  </li>

  <li>
    <b> Reinforcement Learning: An Introduction </b> <a href="https://drive.google.com/file/d/1opPSz5AZ_kVa1uWOdOiveNiBFiEOHjkG/view">[pdf-link]</a> <a href="http://incompleteideas.net/book/the-book-2nd.html">[main-link]</a> <br>
    Second Edition, in progress - MIT Press, Cambridge, MA, 2017 <br>
  </li>

  <li>
    <b> NAME </b> <a href="LINK">[link]</a> <br>
    INFO <br>
  </li>

  </ol>
</div>





